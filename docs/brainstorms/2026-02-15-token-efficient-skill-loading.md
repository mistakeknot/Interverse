# Token-Efficient Skill Loading

**Bead:** Clavain-1lri
**Date:** 2026-02-15
**Status:** Brainstorm complete, ready for strategy

---

## Problem

Inter-* plugin skills treat every invocation as a first-time user. Each run reads the same phase docs, reference files, and signal definitions — even though the agent already knows how drift scanning or flux-drive review works. This wastes tokens on ceremony (reading instructions) instead of work (doing the thing).

### Measured Overhead

| Skill | Total lines | Files to read | Ceremony % | Invocations per /sprint |
|-------|-------------|---------------|-----------|------------------------|
| interwatch doc-watch | 364 | 7 | ~70% | 1 |
| interpath artifact-gen | ~300 | 5+ | ~60% | 1-2 |
| interflux flux-drive | 1,954 | 9 | ~66% | 2-3 |
| clavain brainstorming | 53 | 1 (self-contained) | ~30% | 1 |
| clavain writing-plans | ~100 | 1 (self-contained) | ~30% | 1 |

**Key finding:** Skills that embed instructions inline (brainstorming, writing-plans) cost 70-80% less than skills that require sequential file reads (doc-watch, flux-drive).

### Where Tokens Go (drift scan example)

The interwatch drift scan that ran this session consumed ~30% of post-compaction context to update numbers in two docs:

1. Read SKILL.md (39 lines) — "go read these phase files"
2. Read references/watchables.md (38 lines) — schema definition
3. Read phases/detect.md (79 lines) — signal evaluation instructions
4. Read phases/assess.md (54 lines) — scoring model
5. Read phases/refresh.md (61 lines) — action matrix
6. Read project's watchables.yaml (69 lines)
7. Evaluate signals via Bash (version comparison, component counts, git log)
8. Compute scores and present results
9. Regenerate artifacts (full roadmap rewrite = read 512-line original + write 203-line replacement)

Steps 1-5 are pure ceremony. Steps 7-8 are LLM doing shell-script work. Only steps 6 and 9 need an LLM.

## Proposed Solution: B+C

Two complementary strategies:

### Strategy B: Tiered Loading (compact mode)

Each skill gets a `SKILL-compact.md` (~50-80 lines) containing everything needed for the happy path. The full phase docs are only consulted when edge cases arise.

- **SKILL.md** remains the full modular version (for editing, reference)
- **SKILL-compact.md** is auto-generated by flattening and summarizing
- Skills detect compact mode and load the right file
- A build script (`scripts/gen-compact.sh`) regenerates compact files from full docs

**Auto-generation approach:** A script reads all phase/*.md and reference/*.md files for a skill, extracts the essential algorithm (stripping examples, rationale, and verbose descriptions), and writes a single SKILL-compact.md. The script is deterministic — run it after editing any skill doc.

### Strategy C: Pre-computation Scripts

Move deterministic computation from LLM context to shell scripts:

- **Drift detection:** `scripts/interwatch-scan.sh` outputs JSON with signal scores, confidence tiers, and recommended actions
- **Component counting:** Already exists as `gen-catalog.py` — extend to output JSON for drift comparison
- **Version comparison:** Simple shell script comparing plugin.json vs doc headers
- **Dependency checking:** `bd blocked` already provides this

The LLM reads the pre-computed JSON summary and makes decisions. No signal evaluation loop, no SQLite queries, no git log parsing in context.

### Combined Token Savings (estimated)

| Skill | Current | After B+C | Savings |
|-------|---------|-----------|---------|
| interwatch doc-watch | ~364 lines read | ~80 compact + JSON summary | ~70% |
| interpath artifact-gen | ~300 lines read | ~60 compact + discovery JSON | ~65% |
| interflux flux-drive | ~1,954 lines read | ~200 compact + domain JSON | ~60% |

## Scope

### In Scope

- Auto-generation script for compact SKILL.md files
- Pre-computation script for interwatch drift scanning
- Compact files for the 3 highest-overhead skills (interwatch, interpath, interflux)
- Integration: skills detect and prefer compact mode

### Out of Scope (future)

- Caching skill instructions across sessions (requires Claude Code platform changes)
- Per-invocation token budgets
- Rewriting flux-drive's scoring algorithm as a Python script (too complex for v1)

## Open Questions

1. **Where do compact files live?** Same directory as SKILL.md? Separate `compact/` directory?
2. **How does the skill know to load compact vs full?** Environment variable? Convention in the SKILL.md itself?
3. **Should the auto-gen script use an LLM to summarize, or purely mechanical extraction?** Mechanical is deterministic and free but may lose nuance.
4. **Which plugins get compact files first?** The three highest-overhead ones, or all plugins uniformly?

## Decision

User chose B+C with auto-generation of compact files from full docs. Proceed to strategy/planning.
